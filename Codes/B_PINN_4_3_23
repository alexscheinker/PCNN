#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
@author: Alexander Scheinker
"""


import numpy as np
import h5py

import tensorflow as tf
from tensorflow.keras import mixed_precision

# policy = mixed_precision.Policy('mixed_float16')
# mixed_precision.set_global_policy(policy)

# print('Compute dtype: %s' % policy.compute_dtype)
# print('Variable dtype: %s' % policy.variable_dtype)


from tensorflow.keras import layers
from tensorflow.keras.layers import Input, Dense, Activation, Dropout, Conv3D, Conv3DTranspose, UpSampling2D
from tensorflow.keras.layers import concatenate, Add, MaxPool3D, UpSampling3D, Reshape, Multiply, MaxPool2D
from tensorflow.keras.layers import Conv2DTranspose, Conv2D, Flatten, BatchNormalization
from tensorflow.keras.models import Model

from tensorflow import keras

from tensorflow.keras.regularizers import l2 as l2_reg
from tensorflow.keras.regularizers import l1 as l1_reg
from tensorflow.keras.regularizers import l1_l2 as l1_l2_reg
  
import matplotlib.pyplot as plt
import matplotlib
import time
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm

import random
from scipy.io import loadmat
from scipy import misc
import os
import csv
# from sklearn.preprocessing import QuantileTransformer, StandardScaler

from scipy.ndimage import gaussian_filter
from scipy.ndimage.interpolation import zoom
from scipy import ndimage

import gc
import pickle



PATH_TO_VOLUME_DATA  = '.../Volume_Data/'


#%%

# The 3D volumes have dimensions n_pixels*n_pixels*n_pixels
n_pixels = 128

# Import data (Small data set with first 2 time steps.)

# Charge density
Q = np.zeros([2,n_pixels,n_pixels,n_pixels,1])

# Non-zero charge density locations
Qnz = np.zeros([2,n_pixels,n_pixels,n_pixels,1])

# Electric field components
Ex = np.zeros([2,n_pixels,n_pixels,n_pixels,1])
Ey = np.zeros([2,n_pixels,n_pixels,n_pixels,1])
Ez = np.zeros([2,n_pixels,n_pixels,n_pixels,1])

# Magnetic field components
Bx = np.zeros([2,n_pixels,n_pixels,n_pixels,1])
By = np.zeros([2,n_pixels,n_pixels,n_pixels,1])
Bz = np.zeros([2,n_pixels,n_pixels,n_pixels,1])

# Current density components
Jx = np.zeros([2,n_pixels,n_pixels,n_pixels,1])
Jy = np.zeros([2,n_pixels,n_pixels,n_pixels,1])
Jz = np.zeros([2,n_pixels,n_pixels,n_pixels,1])

# Load the data
for n_load in np.arange(2):

    Q[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Q_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    
    Qnz[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Qnz_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    
    Ex[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Ex_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    Ey[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Ey_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    Ez[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Ez_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    
    Bx[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Bx_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    By[n_load] = np.load(PATH_TO_VOLUME_DATA + f'By_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    Bz[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Bz_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    
    Jx[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Jx_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    Jy[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Jy_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    Jz[n_load] = np.load(PATH_TO_VOLUME_DATA + f'Jz_3D_vol_{n_pixels}_{n_load}.npy').reshape([1,n_pixels,n_pixels,n_pixels,1])
    

# Latent space inputs, un-used, all zeros
z_input = np.zeros([2,8,8,8,1]).astype(np.float32)

# Used to un-normalize PINN and no-physics CNN outputs
Bxyz_all_max = np.load(PATH_TO_VOLUME_DATA + 'Bxyz_max.npy')

# Normalize CNN inputs
J_max_max_all_128 = np.load(PATH_TO_VOLUME_DATA+'J_max_max_all_128.npy')

Jx = Jx/J_max_max_all_128
Jy = Jy/J_max_max_all_128
Jz = Jz/J_max_max_all_128

Bx = Bx/Bxyz_all_max
By = By/Bxyz_all_max
Bz = Bz/Bxyz_all_max

# Make 3D field data for the PINN and No-Physics CNNs for current density
Jxyz = np.zeros([2,n_pixels,n_pixels,n_pixels,3])
Jxyz[:,:,:,:,0] = Jx[:,:,:,:,0]
Jxyz[:,:,:,:,1] = Jy[:,:,:,:,0]
Jxyz[:,:,:,:,2] = Jz[:,:,:,:,0]

Bxyz = np.zeros([2,n_pixels,n_pixels,n_pixels,3])
Bxyz[:,:,:,:,0] = Bx[:,:,:,:,0]
Bxyz[:,:,:,:,1] = By[:,:,:,:,0]
Bxyz[:,:,:,:,2] = Bz[:,:,:,:,0]

# Non-zero charge density locations
Qnz_3D = np.zeros([2,n_pixels,n_pixels,n_pixels,3]).astype(np.float32)
Qnz_3D[:,:,:,:,0] = Qnz[:,:,:,:,0]
Qnz_3D[:,:,:,:,1] = Qnz[:,:,:,:,0]
Qnz_3D[:,:,:,:,2] = Qnz[:,:,:,:,0]



#%%

n_pixels = 128

x_max_all = 0.0012
x_min_all = -1*x_max_all

y_max_all = 0.0012
y_min_all = -1*y_max_all

z_max_all = 0.0022
z_min_all = -1*z_max_all

dx = (x_max_all-x_min_all)/(n_pixels-1)
dy = (y_max_all-y_min_all)/(n_pixels-1)
dz = (z_max_all-z_min_all)/(n_pixels-1)

dt = 1.2e-11

d_dx = np.zeros([3,3,3])
d_dx[0,1,1] = -1
d_dx[2,1,1] = 1
d_dx = tf.keras.initializers.Constant(d_dx/2)

d_dy = np.zeros([3,3,3])
d_dy[1,0,1] = -1
d_dy[1,2,1] = 1
d_dy = tf.keras.initializers.Constant(d_dy/2)

d_dz = np.zeros([3,3,3])
d_dz[1,1,0] = -1
d_dz[1,1,2] = 1
d_dz = tf.keras.initializers.Constant(d_dz/2)

def NN_ddx():
    X = Input(shape = (128,128,128,1))
    X_x = Conv3D(1, kernel_size=3, kernel_initializer=d_dx, strides=[1,1,1], padding='SAME', trainable=False)(X)
    d_dx_model = Model(inputs=[X], outputs=[X_x])
    return d_dx_model

def NN_ddy():
    X = Input(shape = (128,128,128,1))
    X_y = Conv3D(1, kernel_size=3, kernel_initializer=d_dy, strides=[1,1,1], padding='SAME', trainable=False)(X)
    d_dy_model = Model(inputs=[X], outputs=[X_y])
    return d_dy_model

def NN_ddz():
    X = Input(shape = (128,128,128,1))
    X_z = Conv3D(1, kernel_size=3, kernel_initializer=d_dz, strides=[1,1,1], padding='SAME', trainable=False)(X)
    d_dz_model = Model(inputs=[X], outputs=[X_z])
    return d_dz_model

mNN_ddx = NN_ddx()
mNN_ddy = NN_ddy()
mNN_ddz = NN_ddz()

#%%

def Field_model():
    
    # Regularlization
    l2w = 1e-6
    
    # Various resolution image inputs
    X_in = Input(shape = (128,128,128,3))
    
    # Latent space input, all zeros, not used
    ES_in = Input(shape = (8,8,8,1))
    
    qPxPyPz_128 = Conv3D(16, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(X_in)
    qPxPyPz_128 = BatchNormalization()(qPxPyPz_128)
    qPxPyPz_128 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_128)
    qPxPyPz_128 = Conv3D(16, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_128)
    qPxPyPz_128 = BatchNormalization()(qPxPyPz_128)
    qPxPyPz_128 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_128)
    # 128x128x128
    
    qPxPyPz_64 = MaxPool3D(pool_size=(2,2,2))(qPxPyPz_128)
    # 64x64x64
    
    qPxPyPz_64 = Conv3D(32, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_64)
    qPxPyPz_64 = BatchNormalization()(qPxPyPz_64)
    qPxPyPz_64 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_64)
    qPxPyPz_64 = Conv3D(32, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_64)
    qPxPyPz_64 = BatchNormalization()(qPxPyPz_64)
    qPxPyPz_64 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_64)
    # 64x64x64
    
    qPxPyPz_32 = MaxPool3D(pool_size=(2,2,2))(qPxPyPz_64)
    # 32x32x32
    
    qPxPyPz_32 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_32)
    qPxPyPz_32 = BatchNormalization()(qPxPyPz_32)
    qPxPyPz_32 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_32)
    qPxPyPz_32 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_32)
    qPxPyPz_32 = BatchNormalization()(qPxPyPz_32)
    qPxPyPz_32 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_32)
    # 32x32x32
    
    qPxPyPz_16 = MaxPool3D(pool_size=(2,2,2))(qPxPyPz_32)
    # 16x16x16
    
    qPxPyPz_16 = Conv3D(128, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_16)
    qPxPyPz_16 = BatchNormalization()(qPxPyPz_16)
    qPxPyPz_16 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_16)
    qPxPyPz_16 = Conv3D(128, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_16)
    qPxPyPz_16 = BatchNormalization()(qPxPyPz_16)
    qPxPyPz_16 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_16)
    # 16x16x16
    
    qPxPyPz_8 = MaxPool3D(pool_size=(2,2,2))(qPxPyPz_16)
    # 8x8x8
    
    qPxPyPz_8 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_8)
    qPxPyPz_8 = BatchNormalization()(qPxPyPz_8)
    qPxPyPz_8 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_8)
    qPxPyPz_8 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_8)
    qPxPyPz_8 = BatchNormalization()(qPxPyPz_8)
    qPxPyPz_8 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_8)
    # 8x8x8
    qPxPyPz_8 = Conv3D(1, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(qPxPyPz_8)
    qPxPyPz_8 = BatchNormalization()(qPxPyPz_8)
    qPxPyPz_8 = layers.LeakyReLU(alpha=0.1)(qPxPyPz_8)
    # 8x8x8x1
    
    adapt_in = Add()([qPxPyPz_8,ES_in])
    # 8x8x8x1
    
    A_8 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(adapt_in)
    A_8 = BatchNormalization()(A_8)
    A_8 = layers.LeakyReLU(alpha=0.1)(A_8)
    A_8 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(A_8)
    A_8 = BatchNormalization()(A_8)
    A_8 = layers.LeakyReLU(alpha=0.1)(A_8)
    # 8x8x8
    
    A_16 = Conv3DTranspose(64, kernel_size=3, strides=(2,2,2), padding='same', kernel_regularizer=l2_reg(l2w))(A_8)
    A_16 = BatchNormalization()(A_16)
    A_16 = layers.LeakyReLU(alpha=0.1)(A_16)
    # 16x16x16
    A_16 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(A_16)
    A_16 = BatchNormalization()(A_16)
    A_16 = layers.LeakyReLU(alpha=0.1)(A_16)
    A_16 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(A_16)
    A_16 = BatchNormalization()(A_16)
    A_16 = layers.LeakyReLU(alpha=0.1)(A_16)
    # 16x16x16
    
    A_32 = Conv3DTranspose(64, kernel_size=3, strides=(2,2,2), padding='same', kernel_regularizer=l2_reg(l2w))(A_16)
    A_32 = BatchNormalization()(A_32)
    A_32 = layers.LeakyReLU(alpha=0.1)(A_32)
    # 32x32x32
    A_32 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(A_32)
    A_32 = BatchNormalization()(A_32)
    A_32 = layers.LeakyReLU(alpha=0.1)(A_32)
    A_32 = Conv3D(64, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(A_32)
    A_32 = BatchNormalization()(A_32)
    A_32 = layers.LeakyReLU(alpha=0.1)(A_32)
    # 32x32x32
    
    A_64 = Conv3DTranspose(32, kernel_size=3, strides=(2,2,2), padding='same', kernel_regularizer=l2_reg(l2w))(A_32)
    A_64 = BatchNormalization()(A_64)
    A_64 = layers.LeakyReLU(alpha=0.1)(A_64)
    # 64x64x64
    A_64 = Conv3D(32, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(A_64)
    A_64 = BatchNormalization()(A_64)
    A_64 = layers.LeakyReLU(alpha=0.1)(A_64)
    A_64 = Conv3D(32, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(A_64)
    A_64 = BatchNormalization()(A_64)
    A_64 = layers.LeakyReLU(alpha=0.1)(A_64)
    # Ax_64 = Conv3D(1, kernel_size=3, strides=(1,1,1), padding='same', activation='linear')(Ax_64)
    # 64x64x64
    
    A_128 = Conv3DTranspose(16, kernel_size=3, strides=(2,2,2), padding='same', kernel_regularizer=l2_reg(l2w))(A_64)
    A_128 = BatchNormalization()(A_128)
    A_128 = layers.LeakyReLU(alpha=0.1)(A_128)
    # 128x128x128
    A_128 = Conv3D(16, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(A_128)
    A_128 = BatchNormalization()(A_128)
    A_128 = layers.LeakyReLU(alpha=0.1)(A_128)
    A_128 = Conv3D(16, kernel_size=3, strides=(1,1,1), padding='same', kernel_regularizer=l2_reg(l2w))(A_128)
    A_128 = BatchNormalization()(A_128)
    A_128 = layers.LeakyReLU(alpha=0.1)(A_128)
    # 128x128x128
    
    B_xyz = Conv3D(1, kernel_size=3, strides=(1,1,1), padding='same', activation='linear', dtype='float32')(A_128)
    # 128x128x128

    # Define the model
    CNN_model = Model(inputs=[X_in,ES_in], outputs=[B_xyz,adapt_in])

    #Return the model
    return CNN_model

#%%

def PINN_constraint(B_model,Jxyz_in,ES_in,A_cut_now,Qnz_3D_now):
    
    # Predict B field
    Bxyz_now, BL_temp = B_model([Jxyz_in, ES_in, Qnz_3D_now])
    Bx_now = Bxyz_now[:,:,:,:,0]
    By_now = Bxyz_now[:,:,:,:,1]
    Bz_now = Bxyz_now[:,:,:,:,2]
    
    
    # Un-normalize and take derivatives
    Bx_x = mNN_ddx(Bx_now)/dx
    By_y = mNN_ddy(By_now)/dy
    Bz_z = mNN_ddz(Bz_now)/dz
    
    # Sum for divergence
    B_div_now = Bx_x + By_y + Bz_z
    
    # Cut off edges
    B_div_now = B_div_now*A_cut_now
    
    # Weigh low charge regions less
    Q_now_norm = Qnz_3D_now/np.max(Qnz_3D_now)
    B_div_now = B_div_now*(Q_now_norm**2)
    
    
    return Bxyz_now, B_div_now

#%%

def compute_loss(B_model,
                 Jxyz_in,ES_in,A_cut_now,
                 Bxyz_tr,Qnz_3D_now
                 ):
    
    Bxyz_now, B_div_now = PINN_constraint(B_model,Jxyz_in,ES_in,A_cut_now,Qnz_3D_now)
    
    # B field
    loss_Bxyz = tf.reduce_mean(tf.square(Bxyz_now-Bxyz_tr))
    
    # Divergence
    #loss_div = tf.reduce_mean(tf.square(B_div_now))/5000000000
    loss_div = tf.reduce_mean(tf.square(B_div_now))/(2.0*10.0*10.0*500000)
    
    # Total loss
    loss = loss_Bxyz + loss_div

    return loss, loss_Bxyz, loss_div




#%%

def get_grad(B_model,
                 Jxyz_in,ES_in,A_cut_now,
                 Bxyz_tr,Qnz_3D_now
                 ):
    
    with tf.GradientTape(persistent=True) as tape:
        tape.watch(B_model.trainable_variables)
        loss, loss_Bxyz, loss_div = compute_loss(B_model,
                         Jxyz_in,ES_in,A_cut_now,
                         Bxyz_tr,Qnz_3D_now
                         )
        
    gB = tape.gradient(loss, B_model.trainable_variables)
    
    del tape
    
    return loss, gB, loss_Bxyz, loss_div


#%%

# Create Bxyz model

B_PINN_model = Field_model()
lr = 1e-3
optim_B = tf.keras.optimizers.Adam(learning_rate = lr)
B_PINN_model.summary()


#%%

def train_step(B_PINN_model,
                 Jxyz_in,ES_in,A_cut_now,
                 Bxyz_tr,Qnz_3D_now
                 ):
    
    loss, gB, loss_Bxyz, loss_div = get_grad(B_PINN_model,
                     Jxyz_in,ES_in,A_cut_now,
                     Bxyz_tr,Qnz_3D_now
                     )
    
    optim_B.apply_gradients(zip(gB, B_PINN_model.trainable_variables))
    
    return loss, gB, loss_Bxyz, loss_div


#%%

# Number of epochs
N_epochs = 50000

# Number of training data points to look at
Nt = 2

hist_B = []
hist_D = []


n_models_saved_now = 0
t11=time.time()
for n_ep in np.arange(N_epochs):

    for n_t in np.arange(Nt):
        print(f'Starting single step {n_t+1}/{Nt} of epoch {n_ep+1}/{N_epochs}.')
        t1 = time.time()
        
        loss, gB, loss_Bxyz, loss_div = train_step(B_PINN_model, 
                     Jxyz[n_t+0:n_t+1], z_input[n_t:n_t+1], Qnz[n_t+0:n_t+1],
                     Bxyz[n_t+0:n_t+1], Qnz_3D[n_t:n_t+1])
        
        print('\n')
        print(f'Loss Bxyz = {loss_Bxyz:.11f}')
        print(f'Loss B div = {loss_div:.11f}')
        print('\n')

        

        hist_B.append(loss_Bxyz.numpy()) 
        hist_D.append(loss_div.numpy())
        
        
        t2 = time.time()
        print(f'Step time: {t2-t1:2f} seconds')
      

t22=time.time()
print(f'Total time: {t22-t11:2f} seconds')







